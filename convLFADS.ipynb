{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do:\n",
    "\n",
    "# 1- change the loss function to variational loss (recon and kl)\n",
    "# 2- play with hyper-parameters, and loss\n",
    "# 3- check on test error\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from lfads import LFADS_Net\n",
    "from objective import *\n",
    "\n",
    "class conv_block(nn.Module):# *args, **kwargs \n",
    "    def __init__(self, in_f, out_f):\n",
    "        super(conv_block,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(in_f, out_f, \n",
    "                  kernel_size=3, \n",
    "                  padding=1)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1,2,2),\n",
    "                     return_indices=True)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x, ind = self.pool1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        return x, ind\n",
    "        \n",
    "\n",
    "\n",
    "class deconv_block(nn.Module):\n",
    "    def __init__(self, in_f, out_f):\n",
    "        super(deconv_block,self).__init__()\n",
    "        \n",
    "        self.unpool1 = nn.MaxUnpool3d(kernel_size=(1,2,2))\n",
    "        \n",
    "        self.deconv1 = nn.ConvTranspose3d(in_channels=in_f,\n",
    "                                          out_channels=out_f,\n",
    "                                          kernel_size=3,\n",
    "                                          padding=1, \n",
    "                                         )\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x,ind):\n",
    "        \n",
    "        x = self.unpool1(x,ind)\n",
    "        x = self.deconv1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class convVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convVAE,self).__init__()\n",
    "        \n",
    "        in_f = 1\n",
    "        out_f = [2,3]\n",
    "        all_f = [in_f,*out_f]\n",
    "        self.n_layers = 2\n",
    "        \n",
    "        self.video_dim_space = 128\n",
    "        self.video_dim_time = 50\n",
    "        self.final_size = 32\n",
    "        self.final_f = 3\n",
    "        \n",
    "        self.convlayers = nn.ModuleList()\n",
    "        for n in range(0,self.n_layers):\n",
    "            self.convlayers.add_module('{}{}'.format('ce', n),conv_block(all_f[n], all_f[n+1]))\n",
    "#         self.convlayers.add_module('ce1',conv_block(out_f1, out_f2))\n",
    "        \n",
    "        self.deconvlayers = nn.ModuleList()\n",
    "        for n in range(0,self.n_layers):\n",
    "            self.deconvlayers.add_module('{}{}'.format('dec', n),deconv_block(all_f[self.n_layers-n], all_f[self.n_layers-n-1]))\n",
    "#         self.deconvlayers.add_module('dec0',deconv_block(out_f2,out_f1))\n",
    "#         self.deconvlayers.add_module('dec1',deconv_block(out_f1,in_f))\n",
    "#         self.ce1 = conv_block(in_f, out_f1) \n",
    "#         self.ce2 = conv_block(out_f1, out_f2)\n",
    "\n",
    "#         self.dec1 = deconv_block(out_f2,out_f1)\n",
    "#         self.dec2 = deconv_block(out_f1,in_f) \n",
    "\n",
    "        self.lfads = LFADS_Net(self.final_size * self.final_size * self.final_f, output_size = None, factor_size = 4,\n",
    "                 g_encoder_size  = 64, c_encoder_size = 64,\n",
    "                 g_latent_size   = 64, u_latent_size  = 1,\n",
    "                 controller_size = 64, generator_size = 64,\n",
    "                 prior = {'g0' : {'mean' : {'value': 0.0, 'learnable' : True},\n",
    "                                  'var'  : {'value': 0.1, 'learnable' : False}},\n",
    "                          'u'  : {'mean' : {'value': 0.0, 'learnable' : False},\n",
    "                                  'var'  : {'value': 0.1, 'learnable' : True},\n",
    "                                  'tau'  : {'value': 10,  'learnable' : True}}},\n",
    "                 clip_val=5.0, dropout=0.0, max_norm = 200, deep_freeze = False,\n",
    "                 do_normalize_factors=True, device='cpu')\n",
    "\n",
    "        \n",
    "    def forward(self,video):\n",
    "        x = video\n",
    "        Ind = list()\n",
    "        for n, layer in enumerate(self.convlayers):\n",
    "            x, ind1 = layer(x)\n",
    "            Ind.append(ind1)\n",
    "        \n",
    "        x = x.permute(0,2,1,3,4)\n",
    "        x = x.reshape(x.shape[0],x.shape[1],-1)\n",
    "        \n",
    "        x = x.permute(1,0,2)\n",
    "        r,_ = self.lfads(x)\n",
    "        x = r['data']\n",
    "        x = x.permute(1,0,2)\n",
    "        # call LFADS here:\n",
    "        # x should be reshaped for LFADS [time x batch x cells]:\n",
    "        # \n",
    "        # LFADS output should be also reshaped back for the conv decoder\n",
    "        \n",
    "        x = x.reshape(x.shape[0],x.shape[1],self.final_f,self.final_size, self.final_size)\n",
    "        x = x.permute(0,2,1,3,4)\n",
    "\n",
    "        \n",
    "        \n",
    "        for n, layer in enumerate(self.deconvlayers):     \n",
    "            x = layer(x,Ind[self.n_layers-n-1])\n",
    "            \n",
    "\n",
    "#         x, ind1 = self.ce0(video)\n",
    "#         x, ind2 = self.ce1(x)\n",
    "#         x = self.dec0(x,ind2)\n",
    "#         v_p = self.dec1(x,ind1)\n",
    "        \n",
    "\n",
    "#         return v_p\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    \n",
    "    from synthetic_data import generate_lorenz_data, SyntheticCalciumVideoDataset\n",
    "\n",
    "    # convert data to torch.FloatTensor\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    # load the training and test datasets\n",
    "\n",
    "    data_dict = generate_lorenz_data(20, 65, 50, 50, save=False)\n",
    "    cells = data_dict['cells']\n",
    "    traces = data_dict['train_fluor']\n",
    "    train_data = SyntheticCalciumVideoDataset(traces=traces, cells=cells)\n",
    "    test_data = SyntheticCalciumVideoDataset(traces=traces, cells=cells)\n",
    "    \n",
    "    num_workers = 0\n",
    "    # how many samples per batch to load\n",
    "    batch_size = 20\n",
    "\n",
    "    # prepare data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    return train_data, train_loader, test_loader\n",
    "\n",
    "class convLFADS_loss(nn.Module):\n",
    "    def __init__():\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "def train_convVAE(train_loader,test_loader,n_epochs): #model,\n",
    "    model = convVAE()\n",
    "\n",
    "    # number of epochs to train the model\n",
    "#     n_epochs = 30\n",
    "#     train_loader, test_loader = get_data()\n",
    "#     model = convVAE()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # monitor training loss\n",
    "        train_loss = 0.0\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        i = 0\n",
    "        for data in train_loader:\n",
    "#             print(i)\n",
    "            # _ stands in for labels, here\n",
    "            # no need to flatten images\n",
    "            videos = data\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            outputs = model(videos)\n",
    "            # calculate the loss\n",
    "            loss = criterion(outputs, videos)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update running training loss\n",
    "            train_loss += loss.item()*videos.size(0)\n",
    "            i += 1\n",
    "\n",
    "        # print avg training statistics \n",
    "        train_loss = train_loss/len(train_loader)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss\n",
    "            ))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Lorenz data\n",
      "Converting to rates and spikes\n",
      "Converting to fluorescence\n",
      "Train and test split\n",
      "Saving to .//synth_data/lorenz_100\n",
      "Epoch: 1 \tTraining Loss: 20.495386\n",
      "Epoch: 2 \tTraining Loss: 17.015049\n",
      "Epoch: 3 \tTraining Loss: 13.311833\n",
      "Epoch: 4 \tTraining Loss: 11.157027\n",
      "Epoch: 5 \tTraining Loss: 9.906223\n",
      "Epoch: 6 \tTraining Loss: 9.051613\n",
      "Epoch: 7 \tTraining Loss: 8.469227\n",
      "Epoch: 8 \tTraining Loss: 8.045379\n",
      "Epoch: 9 \tTraining Loss: 7.779731\n",
      "Epoch: 10 \tTraining Loss: 7.615138\n"
     ]
    }
   ],
   "source": [
    "train_data, train_loader, test_loader = get_data()\n",
    "train_convVAE(train_loader,test_loader,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
